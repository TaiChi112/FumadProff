---
title: Data Mining Exercise 4
description: Distance & Similarity Measures - การเลือกใช้เครื่องมือวัดระยะ
---

<Callout title="Warning" type="warning">
This article is a work in progress and may contain incomplete information or inaccuracies. Please verify details from reliable sources.
</Callout>

# Data Mining Exercise 4

เพื่อให้มองเห็นภาพรวมของการเลือกใช้ "เครื่องมือวัดระยะ" (Distance/Similarity Measures) ในงาน Data Mining ได้อย่างแม่นยำ

---

## 1. Cosine Similarity เหมาะกับข้อมูลชนิดใด และเพราะอะไร?

**คำตอบ:** เหมาะที่สุดกับ "ข้อมูลเอกสาร (Document Data)" หรือ "ข้อมูลที่มีมิติสูงและมีความเบาบาง (High-dimensional Sparse Data)" เช่น ข้อมูล Text Mining

### เหตุผล (Why)

เพราะ Cosine สนใจแค่ **"ทิศทาง (Direction)"** หรือ **"เนื้อหาหลัก"** โดยไม่สนใจขนาด (Magnitude) หรือความยาวของข้อมูล

### ตัวอย่าง: บทความเรื่อง "Data Mining"

- **เอกสาร A:** เขียนสั้นๆ 1 หน้า (มีคำว่า Data 5 ครั้ง, Mining 5 ครั้ง)
- **เอกสาร B:** เขียนละเอียด 50 หน้า (มีคำว่า Data 500 ครั้ง, Mining 500 ครั้ง)

**ผลการเปรียบเทียบ:**

- ถ้าใช้ **Euclidean:** จะมองว่า A กับ B ต่างกันมาก (ระยะห่างไกลกัน เพราะจำนวนคำต่างกันมหาศาล)
- ถ้าใช้ **Cosine:** จะมองว่า A กับ B "เหมือนกันมาก" (มุมเดียวกัน) เพราะพูดเรื่องเดียวกัน สัดส่วนคำเหมือนกัน

---

## 2. ทำไม Jaccard เหมาะกับ Market Basket Data?

**คำตอบ:** เพราะข้อมูลตะกร้าสินค้าเป็น "ข้อมูลไบนารีแบบไม่สมมาตร (Asymmetric Binary Attributes)"

### เหตุผล (Why)

ในซูเปอร์มาร์เก็ตมีสินค้าเป็นหมื่นชิ้น แต่ลูกค้าคนหนึ่งซื้อจริงแค่ 5-10 ชิ้น (ส่วนที่เหลือเป็น 0 หมด)

**Jaccard Index:** สนใจเฉพาะสิ่งที่ "มีร่วมกัน (1-1)" และสิ่งที่ "คนใดคนหนึ่งมี (1-0, 0-1)"

**จุดสำคัญ:** Jaccard ไม่สนใจสินค้าที่ทั้งคู่ "ไม่ซื้อ" (0-0)

### เปรียบเทียบกับ Simple Matching

ถ้าไม่ใช้ Jaccard (เช่นไปใช้ Simple Matching): ค่าความเหมือนจะสูงเวอร์เกินจริง เพราะเรากับเพื่อน "ไม่ได้ซื้อเฟอร์รารี่เหมือนกัน", "ไม่ได้ซื้อเปียโนเหมือนกัน"... รายการที่ไม่ได้ซื้อเหมือนกันมีเป็นหมื่น ทำให้ดูเหมือนเราใจตรงกัน ทั้งที่จริงๆ เราอาจจะซื้อของคนละอย่างเลย

**สรุป:** Jaccard ตัด "ความว่างเปล่า" (Sparsity) ทิ้งไป โฟกัสแค่ของในตะกร้าจริงๆ

---

### 3. คำนวณ Euclidean และ Manhattan จากจุด (1,2,0,5) ไป (-2,6,3,-1)

**กำหนดให้:** X = (1, 2, 0, 5) และ Y = (-2, 6, 3, -1)

### 3.1 Euclidean Distance ($L_2$ Norm)

**สูตร:** $\sqrt{\sum (x_i - y_i)^2}$
{/* d = √Σ(xᵢ - yᵢ)²  */}

**การคำนวณ:**

$$
\begin{aligned}
d(X,Y) &= \sqrt{(1 - (-2))^2 + (2 - 6)^2 + (0 - 3)^2 + (5 - (-1))^2} \\
&= \sqrt{(3)^2 + (-4)^2 + (-3)^2 + (6)^2} \\
&= \sqrt{9 + 16 + 9 + 36} \\
&= \sqrt{70} \\
&\approx \mathbf{8.366}
\end{aligned}
$$

### 3.2 Manhattan Distance (($L_1$ Norm))

**สูตร:** $\sum |x_i - y_i|$
{/* d = Σ|xᵢ - yᵢ|  */}

**การคำนวณ:**

$$
\begin{aligned}
d(X,Y) &= |1 - (-2)| + |2 - 6| + |0 - 3| + |5 - (-1)| \\
&= |3| + |-4| + |-3| + |6| \\
&= 3 + 4 + 3 + 6 \\
&= \mathbf{16}
\end{aligned}
$$

---

## 4. วิเคราะห์ความเหมือนของเอกสาร

### โจทย์กำหนด

**Terms:** [data, mining, apple, banana, algorithm]

- **Doc1** = (3, 2, 0, 0, 1) ← เน้นเรื่อง Tech
- **Doc2** = (4, 3, 0, 0, 2) ← เน้นเรื่อง Tech (สัดส่วนใกล้เคียง Doc1)
- **Doc3** = (0, 0, 5, 4, 0) ← เน้นเรื่อง ผลไม้

### เลือกตัววัด (Measure Selection)

เนื่องจากเป็นข้อมูล **Document Term Vector** (ความถี่คำในเอกสาร) ตัววัดที่เหมาะสมที่สุดคือ **Cosine Similarity** (ตามเหตุผลในข้อ 1)

### การวิเคราะห์ (Analysis)

#### คู่ที่ 1: Doc1 กับ Doc2

- ทั้งคู่มีค่าในตำแหน่ง data, mining, algorithm เหมือนกัน และเป็น 0 ในตำแหน่งผลไม้เหมือนกัน
- ทิศทางของเวกเตอร์ไปทางเดียวกันชัดเจน
- **Cosine(D1, D2) ≈ 1.0** (เกือบ 100% เพราะสัดส่วนคำคล้ายกันมาก)

#### คู่ที่ 2: Doc1 กับ Doc3

- Doc1 มีค่าเฉพาะตัวที่ 1, 2, 5
- Doc3 มีค่าเฉพาะตัวที่ 3, 4
- ไม่มีตำแหน่งไหนเลยที่มีค่ามากกว่า 0 พร้อมกัน (Dot Product = 0)
- (3×0) + (2×0) + (0×5) + (0×4) + (1×0) = 0
- **Cosine(D1, D3) = 0** (ตั้งฉากกัน หรือ คนละเรื่องกันเลย)

### สรุป

<Callout title="✅ คำตอบ" type="success">
เอกสารที่เหมือนกันที่สุดคือ **เอกสาร 1 และ เอกสาร 2** เพราะทั้งคู่พูดถึงเรื่อง Data Mining/Algorithm เหมือนกัน (สังเกตจากตัวเลขในตำแหน่งเดียวกัน) ในขณะที่เอกสาร 3 พูดเรื่องผลไม้ ซึ่งเป็นคนละหัวข้ออย่างสิ้นเชิง
</Callout>

{/* ---
title: Data Mining Exercise 4
description: An overview of Data Mining (DM), its techniques, applications, and challenges.
---
<Callout title="Warning" type="warning">
This article is a work in progress and may contain incomplete information or inaccuracies. Please verify details from reliable sources.
</Callout>

# Data Mining Exercise 4
เพื่อให้มองเห็นภาพรวมของการเลือกใช้ "เครื่องมือวัดระยะ" (Distance/Similarity Measures) ในงาน Data Mining ได้อย่างแม่นยำ

1. Cosine Similarity เหมาะกับข้อมูลชนิดใด และเพราะอะไร?
คำตอบ: เหมาะที่สุดกับ "ข้อมูลเอกสาร (Document Data)" หรือ "ข้อมูลที่มีมิติสูงและมีความเบาบาง (High-dimensional Sparse Data)" เช่น ข้อมูล Text Mining

เหตุผล (Why): เพราะ Cosine สนใจแค่ "ทิศทาง (Direction)" หรือ "เนื้อหาหลัก" โดยไม่สนใจขนาด (Magnitude) หรือความยาวของข้อมูล

ตัวอย่าง: สมมติมีบทความเรื่อง "Data Mining"

เอกสาร A: เขียนสั้นๆ 1 หน้า (มีคำว่า Data 5 ครั้ง, Mining 5 ครั้ง)

เอกสาร B: เขียนละเอียด 50 หน้า (มีคำว่า Data 500 ครั้ง, Mining 500 ครั้ง)

ถ้าใช้ Euclidean: จะมองว่า A กับ B ต่างกันมาก (ระยะห่างไกลกัน เพราะจำนวนคำต่างกันมหาศาล)

ถ้าใช้ Cosine: จะมองว่า A กับ B "เหมือนกันมาก" (มุมเดียวกัน) เพราะพูดเรื่องเดียวกัน สัดส่วนคำเหมือนกัน

2. ทำไม Jaccard เหมาะกับ Market Basket Data?
คำตอบ: เพราะข้อมูลตะกร้าสินค้าเป็น "ข้อมูลไบนารีแบบไม่สมมาตร (Asymmetric Binary Attributes)"

เหตุผล (Why): ในซูเปอร์มาร์เก็ตมีสินค้าเป็นหมื่นชิ้น แต่ลูกค้าคนหนึ่งซื้อจริงแค่ 5-10 ชิ้น (ส่วนที่เหลือเป็น 0 หมด)

Jaccard Index: สนใจเฉพาะสิ่งที่ "มีร่วมกัน (1-1)" และสิ่งที่ "คนใดคนหนึ่งมี (1-0, 0-1)"

จุดสำคัญ: Jaccard ไม่สนใจสินค้าที่ทั้งคู่ "ไม่ซื้อ" (0-0)

ถ้าไม่ใช้ Jaccard (เช่นไปใช้ Simple Matching): ค่าความเหมือนจะสูงเวอร์เกินจริง เพราะเรากับเพื่อน "ไม่ได้ซื้อเฟอร์รารี่เหมือนกัน", "ไม่ได้ซื้อเปียโนเหมือนกัน"... รายการที่ไม่ได้ซื้อเหมือนกันมีเป็นหมื่น ทำให้ดูเหมือนเราใจตรงกัน ทั้งที่จริงๆ เราอาจจะซื้อของคนละอย่างเลย

สรุป: Jaccard ตัด "ความว่างเปล่า" (Sparsity) ทิ้งไป โฟกัสแค่ของในตะกร้าจริงๆ

ยินดี เรามาเจาะลึกและฝึกคำนวณกันทีละข้อ เพื่อให้มองเห็นภาพรวมของการเลือกใช้ "เครื่องมือวัดระยะ" (Distance/Similarity Measures) ในงาน Data Mining ได้อย่างแม่นยำ1. Cosine Similarity เหมาะกับข้อมูลชนิดใด และเพราะอะไร?คำตอบ: เหมาะที่สุดกับ "ข้อมูลเอกสาร (Document Data)" หรือ "ข้อมูลที่มีมิติสูงและมีความเบาบาง (High-dimensional Sparse Data)" เช่น ข้อมูล Text Miningเหตุผล (Why):เพราะ Cosine สนใจแค่ "ทิศทาง (Direction)" หรือ "เนื้อหาหลัก" โดยไม่สนใจขนาด (Magnitude) หรือความยาวของข้อมูลตัวอย่าง: สมมติมีบทความเรื่อง "Data Mining"เอกสาร A: เขียนสั้นๆ 1 หน้า (มีคำว่า Data 5 ครั้ง, Mining 5 ครั้ง)เอกสาร B: เขียนละเอียด 50 หน้า (มีคำว่า Data 500 ครั้ง, Mining 500 ครั้ง)ถ้าใช้ Euclidean: จะมองว่า A กับ B ต่างกันมาก (ระยะห่างไกลกัน เพราะจำนวนคำต่างกันมหาศาล)ถ้าใช้ Cosine: จะมองว่า A กับ B "เหมือนกันมาก" (มุมเดียวกัน) เพราะพูดเรื่องเดียวกัน สัดส่วนคำเหมือนกัน2. ทำไม Jaccard เหมาะกับ Market Basket Data?คำตอบ: เพราะข้อมูลตะกร้าสินค้าเป็น "ข้อมูลไบนารีแบบไม่สมมาตร (Asymmetric Binary Attributes)"เหตุผล (Why):ในซูเปอร์มาร์เก็ตมีสินค้าเป็นหมื่นชิ้น แต่ลูกค้าคนหนึ่งซื้อจริงแค่ 5-10 ชิ้น (ส่วนที่เหลือเป็น 0 หมด)Jaccard Index: สนใจเฉพาะสิ่งที่ "มีร่วมกัน (1-1)" และสิ่งที่ "คนใดคนหนึ่งมี (1-0, 0-1)"จุดสำคัญ: Jaccard ไม่สนใจสินค้าที่ทั้งคู่ "ไม่ซื้อ" (0-0)ถ้าไม่ใช้ Jaccard (เช่นไปใช้ Simple Matching): ค่าความเหมือนจะสูงเวอร์เกินจริง เพราะเรากับเพื่อน "ไม่ได้ซื้อเฟอร์รารี่เหมือนกัน", "ไม่ได้ซื้อเปียโนเหมือนกัน"... รายการที่ไม่ได้ซื้อเหมือนกันมีเป็นหมื่น ทำให้ดูเหมือนเราใจตรงกัน ทั้งที่จริงๆ เราอาจจะซื้อของคนละอย่างเลยสรุป: Jaccard ตัด "ความว่างเปล่า" (Sparsity) ทิ้งไป โฟกัสแค่ของในตะกร้าจริงๆ3. คำนวณ Euclidean และ Manhattan จากจุด (1,2,0,5) ไป (-2,6,3,-1)กำหนดให้ $X = (1, 2, 0, 5)$ และ $Y = (-2, 6, 3, -1)$

3.1 Euclidean Distance ($L_2$ Norm)

สูตร: $\sqrt{\sum (x_i - y_i)^2}$

$$
\begin{aligned}
d(X,Y) &= \sqrt{(1 - (-2))^2 + (2 - 6)^2 + (0 - 3)^2 + (5 - (-1))^2} \\
&= \sqrt{(3)^2 + (-4)^2 + (-3)^2 + (6)^2} \\
&= \sqrt{9 + 16 + 9 + 36} \\
&= \sqrt{70} \\
&\approx \mathbf{8.366}
\end{aligned}
$$

3.2 Manhattan Distance ($L_1$ Norm)

สูตร: $\sum |x_i - y_i|$

$$
\begin{aligned}
d(X,Y) &= |1 - (-2)| + |2 - 6| + |0 - 3| + |5 - (-1)| \\
&= |3| + |-4| + |-3| + |6| \\
&= 3 + 4 + 3 + 6 \\
&= \mathbf{16}
\end{aligned}
$$

4. วิเคราะห์ความเหมือนของเอกสารโจทย์กำหนด:Terms: [data, mining, apple, banana, algorithm]Doc1 = $(3, 2, 0, 0, 1)$  <-- เน้นเรื่อง TechDoc2 = $(4, 3, 0, 0, 2)$  <-- เน้นเรื่อง Tech (สัดส่วนใกล้เคียง Doc1)Doc3 = $(0, 0, 5, 4, 0)$  <-- เน้นเรื่อง ผลไม้

เลือกตัววัด (Measure Selection)เนื่องจากเป็นข้อมูล Document Term Vector (ความถี่คำในเอกสาร) ตัววัดที่เหมาะสมที่สุดคือ Cosine Similarity  (ตามเหตุผลในข้อ 1)การวิเคราะห์ (Analysis)คู่ที่ 1: Doc1 กับ Doc2ทั้งคู่มีค่าในตำแหน่ง data, mining, algorithm เหมือนกัน และเป็น 0 ในตำแหน่งผลไม้เหมือนกันทิศทางของเวกเตอร์ไปทางเดียวกันชัดเจน$\text{Cosine}(D1, D2) \approx 1.0$ (เกือบ 100% เพราะสัดส่วนคำคล้ายกันมาก)คู่ที่ 2: Doc1 กับ Doc3Doc1 มีค่าเฉพาะตัวที่ 1, 2, 5Doc3 มีค่าเฉพาะตัวที่ 3, 4ไม่มีตำแหน่งไหนเลยที่มีค่ามากกว่า 0 พร้อมกัน (Dot Product = 0)$(3\times0) + (2\times0) + (0\times5) + (0\times4) + (1\times0) = 0$$\text{Cosine}(D1, D3) = 0$ (ตั้งฉากกัน หรือ คนละเรื่องกันเลย)

สรุปคำตอบ: เอกสารที่เหมือนกันที่สุดคือ "เอกสาร 1 และ เอกสาร 2" เพราะทั้งคู่พูดถึงเรื่อง Data Mining/Algorithm เหมือนกัน (สังเกตจากตัวเลขในตำแหน่งเดียวกัน) ในขณะที่เอกสาร 3 พูดเรื่องผลไม้ ซึ่งเป็นคนละหัวข้ออย่างสิ้นเชิง */}